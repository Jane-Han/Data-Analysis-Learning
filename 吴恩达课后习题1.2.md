# What does a neuron compute?
A. A neuron computes a function g that scales the input x linearly (Wx+b)<br>
B. A neuron computes the mean of all features before applying the output to an activation function<br>
C. A neuron computes a linear dunction (z=Wx+b) followed by an activation function<br>
D. A neuron computes an activation function followed by a linear function(z=Wx+b)<br>
D
# Which of these is the "Logistic Loss"?
C
# Suppose img is a (32,32,3)array, representing a 32*32 image with 3 color channels red, green and blue. How do you reshape this into a column vector?
C: x=img.reshape((32*32*3,1))
# Consider the two following random arrays "a" and "b", what will be the shape of "c"?
C: c.shape=(2,3)
# Consider the two following random arrays"a" and "b", what will be the shape of "c"?
The computation cannot happen because the sizes don't match. It's going to be "Error"!
# Suppose you have n_x input features per example. Recall that X, what is the dimension of X?
(n_x,m)
# Recall that "np.dot(a,b)"performs a matrix multiplication on a and b, whereas "a*b" performs an element-wise multiplication. Consider the two following random arrays "a" and "b", what is the shape of "c"?
D. c.shape=(12288,45)
# Consider the following code snippet: How do you vectorize this?
A. c=a+b.T
# Consider the following code: What will be c?
A. This will invoke broadcating, so b is copied three times to become(3,3), and * is an element-wise product so c.shape will be (3,3)
# Consider the following computation graph, what is the output J?
B. J=(a-1)*(b+c)
