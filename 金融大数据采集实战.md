# 金融大数据采集实战
## 数据采集
### 实时数据采集： Flume/Logstash 按事件驱动
- Flume：分为Source、channel和sink模块。支持简单的数据清洗，也可装第三方插件进行数据预处理；具有完整事务机制；支持数据持久化。<br>Source分为驱动和轮询方式，memory channel无持久化，File/ JDBC channel 具有持久化， Sink用于数据存储。<br>连不同channel可将数据进行分类，在多个Flume之间传输，数据会进行压缩和加密。
- Logstash: 主要用于日志采集，具备数据预处理能力。无完整的事务机制；不支持数据持久化。<br>分为inputs，filter(可选)，outputs模块。
### 离线数据采集： Loader 按时间驱动
- 可视化操作界面；离线批量数据采集；支持多种数据源；定时调度，周期执行。<br>
## 数据存储： HDFS/HBase/Redis/Kafka
- HDFS：高容错性；高吞吐量；大文件存储；不适合大量小文件存储；不适合低延迟数据读取。<br> 数据通过128MB的Block块存储，3个副本分别置于3台服务器上。<br>
分为namecode和datacode，其中namecode负责存储与管理，datacode用于存储用户数据并进行数据读写。
- HBase：基于BIGDATA的分布式NOSQL数据库，具有高可靠性，高性能；低延迟访问；高容量；面向列，可伸缩；支持非结构化数据；需要HDFS支持;拓展成本低；缺乏完整的事务机制。<br>
分为HMaster和ReqionServer两个模块。其中HMaster主要负责表的增删改查和负载均衡；RegionServer主要用于表数据增删改查和数据存储，且只负责一套服务器上的读写服务。
- Redis：内存型Key Value数据库。具有高性能，低延迟；支持数据持久化；支持多种数据结构；支持数据备份。
- Kafka：基于发布订阅的消息系统。具有高吞吐，低延迟；分布式部署，容量大；磁盘存储；部署成本低。
## 分析与挖掘常用工具
### 离线：Mapreduce/Hive/Spark
- Mapreduce:用于大规模数据集并行计算的计算引擎：基于磁盘的一种计算框架<br>分布式部署；map。reduce两步计算；易编程，高可靠，高容错；支持多种数据格式
- Spark：用于大规模数据集并行计算的计算引擎。基于内存，高可靠，高性能；集离线，实时，图计算，机器学习于一体；兼容Hadoop体系，业务应用广泛<br>
可以把数据存在HDFS中，也可以用Yarn/Standalone/Messos做资源分配。
- Hive：分布式数据仓库工具（基于磁盘）。<br>
基于Hadoop、高容量、高容错；支持Mapreduce、spark两种计算引擎；支持SQL语法，易用
### 实时：Storm/Flink/Spark
- Storm：分布式实时计算引擎，用于流计算(数据不储存就计算)<br>
具有实时响应，低延迟；完善的事务机制；消息处理严格有序。
- Flink： 批处理和流处理结合的计算引擎。<br>
具有高容错/高可靠特点；高吞吐量/低延迟；数据只处理一次
- Elastric Search：分布式全文搜索引擎。<br>
简单、易部署；性能可靠、实时性好。
- Impala：实时数据仓库工具（基于内存）。<br>
基于内存，速度快；兼容Hadoop系统；与Hive语法相同，学习成本低。
## 可视化常用工具
- Echarts：可高度个性化定制的数据可视化图表<br>
- Kibana：针对ElastricSearch的开源分析及可视化平台<br>
## 协作常用工具
- zokeeper：分布式服务框架（小型数据库）<br>
分布式锁服务；文件系统服务；注册服务；奇数个部署<br>
访问kafka存放信息时，先访问zookeeper去找topic；HBase的元数据表的路由地址信息放在zookeeper中。
- Yarn：分布式资源管理器
提供统一的资源调度；支持多种调度模式；支持多种计算框架
## 工作流常用工具
- Ooize：工作流调度管理工具
支持多种工作引擎；支持多种计算框架
- Azkaban： 工作流调度管理工具
图像化操作；支持多种计算框架
## 商业套件：
商业版较开源版。版本更稳定，向导式安装，具备运维管理界面，权限管理图形化。
- FusionInsight HD： 华为基于开源系统开发的分布式数据处理系统
- CDH：是Cloudera基于开源系统开发的大数据处理事务
- HDP：Horrtonworks开发的企业级大数据平台
