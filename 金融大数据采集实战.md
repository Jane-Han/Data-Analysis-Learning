# 金融大数据采集实战
## 数据采集
### 实时数据采集： Flume/Logstash 按事件驱动
- Flume：分为Source、channel和sink模块。支持简单的数据清洗，也可装第三方插件进行数据预处理；具有完整事务机制；支持数据持久化。<br>Source分为驱动和轮询方式，memory channel无持久化，File/ JDBC channel 具有持久化， Sink用于数据存储。<br>连不同channel可将数据进行分类，在多个Flume之间传输，数据会进行压缩和加密。
- Logstash: 主要用于日志采集，具备数据预处理能力。无完整的事务机制；不支持数据持久化。<br>分为inputs，filter(可选)，outputs模块。
### 离线数据采集： Loader 按时间驱动
- 可视化操作界面；离线批量数据采集；支持多种数据源；定时调度，周期执行。<br>
## 数据存储： HDFS/HBase/Redis/Kafka
- HDFS：高容错性；高吞吐量；大文件存储；不适合大量小文件存储；不适合低延迟数据读取。<br> 数据通过128MB的Block块存储，3个副本分别置于3台服务器上。<br>
分为namecode和datacode，其中namecode负责存储与管理，datacode用于存储用户数据并进行数据读写。
- HBase：基于BIGDATA的分布式NOSQL数据库，具有高可靠性，高性能；低延迟访问；高容量；面向列，可伸缩；支持非结构化数据；需要HDFS支持;拓展成本低；缺乏完整的事务机制。<br>
分为HMaster和ReqionServer两个模块。其中HMaster主要负责表的增删改查和负载均衡；RegionServer主要用于表数据增删改查和数据存储，且只负责一套服务器上的读写服务。
- Redis：内存型Key Value数据库。具有高性能，低延迟；支持数据持久化；支持多种数据结构；支持数据备份。
- Kafka：基于发布订阅的消息系统。具有高吞吐，低延迟；分布式部署，容量大；磁盘存储；部署成本低。
## 分析与挖掘常用工具
### 离线：Mapreduce/Hive/Spark
- Mapreduce:用于大规模数据集并行计算的计算引擎：基于磁盘的一种计算框架<br>分布式部署；map。reduce两步计算；易编程，高可靠，高容错；支持多种数据格式
- Spark：用于大规模数据集并行计算的计算引擎。基于内存，高可靠，高性能；集离线，实时，图计算，机器学习于一体；兼容Hadoop体系，业务应用广泛<br>
可以把数据存在HDFS中，也可以用Yarn/Standalone/Messos做资源分配。
### 实时：Storm/Flink/Spark
- Storm：分布式实时计算引擎，用于流计算(数据不储存就计算)<br>
具有实时响应，低延迟；完善的事务机制；消息处理严格有序。
- Flink： 批处理和流处理结合的计算引擎。<br>
具有高容错/高可靠特点；高吞吐量/低延迟；数据只处理一次
